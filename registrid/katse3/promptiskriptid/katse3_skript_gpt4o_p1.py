#Kood, registrite tÃ¶Ã¶rÃ¼hma 3. katse tarvis. EesmÃ¤rk on OpenAI mudelile kaasa anda korpusest andmed, mida ta analÃ¼Ã¼sima peab.
#Kui kontekst on liiga suur, siis see vektoriseeritakse.
#Autor: Eleri Aedmaa
import os
import csv
import openai
import pickle
import faiss
import tiktoken
import pandas as pd
import re
import time
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer

# --- Konfiguratsioon ---
client = openai.OpenAI()
MODEL = "gpt-4o"
EMBED_MODEL = SentenceTransformer("intfloat/multilingual-e5-base")
DATA_FOLDER = "contexts"
OUTPUT_FOLDER = "vastused"
FINAL_CSV = "vastused_koond.csv"

os.makedirs(OUTPUT_FOLDER, exist_ok=True)
os.makedirs("vector_cache", exist_ok=True)

# --- Abi funktsioonid ---
def tokenize_length(text: str, model=MODEL):
    enc = tiktoken.encoding_for_model(model)
    return len(enc.encode(text))

def build_faiss_index(chunks: List[str]):
    passages = [f"passage: {chunk}" for chunk in chunks]
    embeddings = EMBED_MODEL.encode(passages, show_progress_bar=False)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return index, embeddings

def save_index(index, chunks, path):
    faiss.write_index(index, f"{path}.faiss")
    with open(f"{path}_chunks.pkl", "wb") as f:
        pickle.dump(chunks, f)

def load_index(path):
    index = faiss.read_index(f"{path}.faiss")
    with open(f"{path}_chunks.pkl", "rb") as f:
        chunks = pickle.load(f)
    return index, chunks

def ensure_index_exists(word: str, full_lines: List[str]):
    index_path = os.path.join("vector_cache", word)
    if os.path.exists(index_path + ".faiss") and os.path.exists(index_path + "_chunks.pkl"):
        return load_index(index_path)
    index, _ = build_faiss_index(full_lines)
    save_index(index, full_lines, index_path)
    return index, full_lines

def get_relevant_chunks_max(query: str, chunks: List[str], index, max_k=None):
    query_vec = EMBED_MODEL.encode([f"query: {query}"], show_progress_bar=False)
    D, I = index.search(query_vec, len(chunks))
    sorted_chunks = [chunks[i] for i in I[0]]
    if max_k:
        return sorted_chunks[:max_k]
    return sorted_chunks

def get_completion(prompt: str, context: str) -> str:
    response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": context}
        ],
        max_tokens=16000,
        temperature=0.1
    )
    return response.choices[0].message.content

def sanitize_filename(text):
    return re.sub(r'[<>:"/\\|?*]', '_', text)[:100]

# --- PROMPT (tÃ¤pselt sinu sÃµnastus) ---
def create_analysis_prompt(word: str):
    return f"""Oled eesti keele sÃµnaraamatu koostaja. Sinu Ã¼lesanne on analÃ¼Ã¼sida sÃµna â€{word}" kasutust etteantud tekstimaterjalis ja otsustada, kas selle tÃ¤hendustele tuleks lisada registrimÃ¤rgend.

Vasta jÃ¤rgmistele kÃ¼simustele, tuginedes ainult etteantud materjalile:

1. Nimeta sÃµna â€{word}" kÃµik tÃ¤hendused, mida etteantud tekstides nÃ¤ed. Ã„ra erista alammÃµisteid erinevateks tÃ¤hendusteks (nÃ¤iteks â€alukad" ei tÃ¤henda eraldi â€aluspesu" ja â€vanaema aluspÃ¼kse", vaid Ã¼ksnes â€aluspesu").

2. Nimeta sÃµna â€{word}" erinevate tÃ¤henduste arv.

3. Iga tÃ¤henduse juurde lisa, kas sÃµna on selles tÃ¤henduses sage, keskmine vÃµi vÃ¤hene. SagedusrÃ¼hm vali vÃµrdluses sÃµna teiste tÃ¤hendustega.

4. Too iga tÃ¤henduse kohta etteantud materjalist 5 nÃ¤itelauset, kus â€{word}" selles tÃ¤henduses esineb.

5. Otsusta sÃµna iga tÃ¤henduse kohta, kas seda kasutatakse pigem informaalsetes vÃµi neutraalsetes/formaalsetes tekstides? Kui sa ei oska eristust teha, sest see ei tule selgelt esile, siis Ã¼tle, et â€ei kohaldu". Palun pÃµhjenda oma valikut 5-10 lausega.

6. Ãœtle iga tÃ¤henduse juures, kui kindel sa oled oma vastuses selle kohta, kas tÃ¤hendust kasutatakse informaalsetes vÃµi neutraalsetes/formaalsetes tekstides vÃµi â€ei kohalduâ€œ. Vali, kas oled â€vÃ¤ga kindelâ€œ, â€pigem kindelâ€œ, â€pigem ebakindelâ€œ, â€vÃ¤ga ebakindelâ€œ.

7. Kui mÃµnda tÃ¤hendust kasutatakse tekstides mingil viisil eripÃ¤raselt, siis vali sellele sobiv registrimÃ¤rgend jÃ¤rgmistest:

- halvustav (vali siis, kui sÃµna selles tÃ¤henduses on kedagi vÃµi midagi laitev, mahategev, halvaks pidav, sÃµimav; nÃ¤iteks ajuhÃ¤lvik, debiilik, inimrÃ¤mps)
- harv (vali siis, kui sÃµna selles tÃ¤henduses pole levinud, andmeid on vÃ¤he; nÃ¤iteks ahvatama, mÃµistamisi, siinap). MÃ¤rgend â€harv" vali iga kord, kui tÃ¤hendust leidub etteantud tekstimaterjalis vÃ¤he.
- kÃµnekeelne (vali siis, kui sÃµna selles tÃ¤henduses on formaalsest keelekasutusest vabamasse registrisse kuuluv; nÃ¤iteks igastahes, nokats, Ã¤ra flippima)
- lastekeelne (vali siis, kui sÃµna selles tÃ¤henduses on lastekeelde kuuluv, sellele iseloomulik; nÃ¤iteks jallu, kÃ¤tu, nuku)
- luulekeelne (vali siis, kui sÃµna selles tÃ¤henduses on luulele iseloomulik, luulele omased, poeetilised vÃ¤ljendusvahendid; nÃ¤iteks ehavalu, koidukuld, meeleheit)
- murdekeelne (vali siis, kui sÃµna selles tÃ¤henduses on murdes, murdekeeles kirjutatud, ei ole standardkeelne; nÃ¤iteks hÃ¤mmelgas, jÃµÃµrdlik, kidelema)
- rahvapÃ¤rane (vali siis, kui sÃµna selles tÃ¤henduses on rahva seas levinud, aga pole ametlik termin, tihti nÃ¤iteks kuude, taimede, loomade, haiguste, sugulaste nimetused; nÃ¤iteks heinakuu, jooksva, mÃ¤nniseen)
- stiilitundlik (vali siis, kui sÃµna selles tÃ¤henduses on neutraalsest sÃµnastusest stiililiselt millegi poolest nÃ¤htavalt markeeritud, peene stiilitajuga, kÃµrgstiilsem; nÃ¤iteks armastet, inimesepoeg, modern)
- vananenud (vali siis, kui sÃµna selles tÃ¤henduses on iganenud, aegunud; nÃ¤iteks automobiil, aeroplaan, drogist)
- vulgaarne (vali siis, kui sÃµna selles tÃ¤henduses on labane, jÃ¤me, tahumatu; nÃ¤iteks hoorapoeg, koinima, perse saatma)

Iga valiku korral pÃµhjenda 5-10 lausega, miks just see mÃ¤rgend sobib. Igal informaalsel tÃ¤hendusel peab olema vÃ¤hemalt Ã¼ks mÃ¤rgend. Kui sobib mitu, too mitu. Neutraalsele/formaalsele ja â€ei kohalduâ€œ tÃ¤hendusele lisa mÃ¤rgend ainult siis, kui see tundub tekstimaterjali pÃµhjal vajalik.

OLULINE: PÃ¤rast kÃ¼simustele vastamist anna oma vastused TÃ„PSELT jÃ¤rgmises struktureeritud formaadis parsimiseks. Kasuta erinevat eraldajat (Â§Â§Â§) iga tÃ¤henduse andmete vahel:

--- STRUKTUREERITUD VASTUS ALGAB ---
TÃ„HENDUSED: tÃ¤hendus1Â§Â§Â§tÃ¤hendus2Â§Â§Â§tÃ¤hendus3
TÃ„HENDUSTE-ARV: 3
SAGEDUSED: tÃ¤hendus1-sageÂ§Â§Â§tÃ¤hendus2-keskmineÂ§Â§Â§tÃ¤hendus3-vÃ¤hene
NÃ„ITED: tÃ¤hendus1-laus1|laus2|laus3|laus4|laus5Â§Â§Â§tÃ¤hendus2-laus1|laus2|laus3|laus4|laus5Â§Â§Â§tÃ¤hendus3-laus1|laus2|laus3|laus4|laus5
REGISTRID: tÃ¤hendus1-neutraalsetes-formaalsetesÂ§Â§Â§tÃ¤hendus2-informaalsetesÂ§Â§Â§tÃ¤hendus3-ei kohaldu
REGISTRI-PÃ•HJENDUSED: tÃ¤hendus1-... 5â€“10 lauset ...Â§Â§Â§tÃ¤hendus2-... 5â€“10 lauset ...Â§Â§Â§tÃ¤hendus3-... 5â€“10 lauset ...
REGISTRI-KINDLUS: tÃ¤hendus1-vÃ¤ga kindelÂ§Â§Â§tÃ¤hendus2-pigem kindelÂ§Â§Â§tÃ¤hendus3-pigem ebakindel
MÃ„RGENDID: tÃ¤hendus1-ei-kohalduÂ§Â§Â§tÃ¤hendus2-kÃµnekeelne,rahvapÃ¤raneÂ§Â§Â§tÃ¤hendus3-harv
MÃ„RGENDITE-PÃ•HJENDUSED: tÃ¤hendus1-ei-kohalduÂ§Â§Â§tÃ¤hendus2-... 5â€“10 lauset ...Â§Â§Â§tÃ¤hendus3-... 5â€“10 lauset ...
--- STRUKTUREERITUD VASTUS LÃ•PEB ---"""

# --- Parandatud parsimise funktsioon ---
def parse_analysis_response(txt: str, word: str) -> List[Dict[str, Any]]:
    """
    Tagastab listi, kus iga element on Ã¼ks tÃ¤hendus koos kÃµigi andmetega
    """
    results = []
    try:
        structured_match = re.search(
            r'--- STRUKTUREERITUD VASTUS ALGAB ---(.*?)--- STRUKTUREERITUD VASTUS LÃ•PEB ---',
            txt, re.DOTALL
        )
        structured_text = structured_match.group(1) if structured_match else txt
        lines = structured_text.split('\n')
        data = {}
        for line in lines:
            line = line.strip()
            if ':' in line and not line.startswith('http'):
                key, value = line.split(':', 1)
                data[key.strip()] = value.strip()

        # TÃ¤hendused
        meanings = []
        if 'TÃ„HENDUSED' in data:
            meanings = [t.strip() for t in data['TÃ„HENDUSED'].split('Â§Â§Â§') if t.strip()]

        # Sagedused
        freq = []
        if 'SAGEDUSED' in data:
            for item in data['SAGEDUSED'].split('Â§Â§Â§'):
                if '-' in item:
                    freq.append(item.split('-', 1)[1].strip())
                else:
                    freq.append(item.strip())

        # NÃ¤ited (5 lauset, kuid vÃµtame kÃµik, mis antud)
        examples = []
        if 'NÃ„ITED' in data:
            for item in data['NÃ„ITED'].split('Â§Â§Â§'):
                if '-' in item:
                    ex = item.split('-', 1)[1].strip().replace('|', ' | ')
                    examples.append(ex)
                else:
                    examples.append(item.strip())

        # Registrid
        registers = []
        if 'REGISTRID' in data:
            for item in data['REGISTRID'].split('Â§Â§Â§'):
                registers.append(item.split('-', 1)[1].strip() if '-' in item else item.strip())

        # Registri pÃµhjendused
        reg_just = []
        if 'REGISTRI-PÃ•HJENDUSED' in data:
            for item in data['REGISTRI-PÃ•HJENDUSED'].split('Â§Â§Â§'):
                reg_just.append(item.split('-', 1)[1].strip() if '-' in item else item.strip())

        # Registri kindlus
        reg_conf = []
        if 'REGISTRI-KINDLUS' in data:
            for item in data['REGISTRI-KINDLUS'].split('Â§Â§Â§'):
                reg_conf.append(item.split('-', 1)[1].strip() if '-' in item else item.strip())

        # MÃ¤rgendid
        tags = []
        if 'MÃ„RGENDID' in data:
            for item in data['MÃ„RGENDID'].split('Â§Â§Â§'):
                tags.append(item.split('-', 1)[1].strip() if '-' in item else item.strip())

        # MÃ¤rgendite pÃµhjendused
        tag_just = []
        if 'MÃ„RGENDITE-PÃ•HJENDUSED' in data:
            for item in data['MÃ„RGENDITE-PÃ•HJENDUSED'].split('Â§Â§Â§'):
                tag_just.append(item.split('-', 1)[1].strip() if '-' in item else item.strip())

        # Koosta read
        total_meanings = data.get('TÃ„HENDUSTE-ARV', str(len(meanings)))
        for i, meaning in enumerate(meanings):
            fval = freq[i] if i < len(freq) else "ei mÃ¤Ã¤ratletud"
            exval = examples[i] if i < len(examples) else "ei leitud"
            reg = registers[i] if i < len(registers) else "ei mÃ¤Ã¤ratletud"
            rj = reg_just[i] if i < len(reg_just) else "ei mÃ¤Ã¤ratletud"
            rc = reg_conf[i] if i < len(reg_conf) else "pigem ebakindel"
            tag_text = tags[i] if i < len(tags) else "ei-kohaldu"
            tj = tag_just[i] if i < len(tag_just) else "ei-kohaldu"

            tag_list = []
            if tag_text and tag_text != "ei-kohaldu":
                tag_list = [m.strip() for m in tag_text.split(',') if m.strip()]

            if not tag_list or tag_text == "ei-kohaldu":
                results.append({
                    "SÃµna": word,
                    "TÃ¤henduse nr": i + 1,
                    "TÃ¤hendus": meaning,
                    "TÃ¤henduste arv kokku": total_meanings,
                    "Sagedus": fval,                          # sage / keskmine / vÃ¤hene
                    "NÃ¤ited": exval,                          # 5 lauset, kui on
                    "Tekstiregister": reg,                    # informaalsetes / neutraalsetes-formaalsetes / ei kohaldu
                    "Registri pÃµhjendus": rj,                 # 5â€“10 lauset
                    "Registri kindlus": rc,                   # vÃ¤ga kindel / pigem kindel / pigem ebakindel / vÃ¤ga ebakindel
                    "RegistrimÃ¤rk": "ei-kohaldu",
                    "MÃ¤rgendi pÃµhjendus": "ei-kohaldu"
                })
            else:
                for mtag in tag_list:
                    results.append({
                        "SÃµna": word,
                        "TÃ¤henduse nr": i + 1,
                        "TÃ¤hendus": meaning,
                        "TÃ¤henduste arv kokku": total_meanings,
                        "Sagedus": fval,
                        "NÃ¤ited": exval,
                        "Tekstiregister": reg,
                        "Registri pÃµhjendus": rj,
                        "Registri kindlus": rc,
                        "RegistrimÃ¤rk": mtag,
                        "MÃ¤rgendi pÃµhjendus": (tj if tj != "ei-kohaldu" else "ei leitud")
                    })

            # Konsooli lÃ¼hilogid
            print(f"   âœ… TÃ¤hendus {i+1}: {meaning}")
            print(f"      ğŸ“ˆ Sagedus: {fval}")
            print(f"      ğŸ“Š Register: {reg}  ({rc})")
            print(f"      ğŸ” Reg.pÃµhjendus: {rj[:100]}{'...' if len(rj) > 100 else ''}")
            print(f"      ğŸ·ï¸ MÃ¤rgend(id): {tag_text}")
            if tj != "ei-kohaldu":
                print(f"      ğŸ“ MÃ¤rgendi pÃµhjendus: {tj[:100]}{'...' if len(tj) > 100 else ''}")

    except Exception as e:
        print(f"   âš ï¸ Parsimise viga: {e}")
        import traceback
        traceback.print_exc()
        results.append({
            "SÃµna": word,
            "TÃ¤henduse nr": 1,
            "TÃ¤hendus": "parsimise viga",
            "TÃ¤henduste arv kokku": 0,
            "Sagedus": "ei mÃ¤Ã¤ratletud",
            "NÃ¤ited": "ei leitud",
            "Tekstiregister": "ei mÃ¤Ã¤ratletud",
            "Registri pÃµhjendus": "ei mÃ¤Ã¤ratletud",
            "Registri kindlus": "pigem ebakindel",
            "RegistrimÃ¤rk": "ei-kohaldu",
            "MÃ¤rgendi pÃµhjendus": "ei-kohaldu"
        })

    if not results:
        results.append({
            "SÃµna": word,
            "TÃ¤henduse nr": 1,
            "TÃ¤hendus": "ei mÃ¤Ã¤ratletud",
            "TÃ¤henduste arv kokku": 0,
            "Sagedus": "ei mÃ¤Ã¤ratletud",
            "NÃ¤ited": "ei leitud",
            "Tekstiregister": "ei mÃ¤Ã¤ratletud",
            "Registri pÃµhjendus": "ei mÃ¤Ã¤ratletud",
            "Registri kindlus": "pigem ebakindel",
            "RegistrimÃ¤rk": "ei-kohaldu",
            "MÃ¤rgendi pÃµhjendus": "ei-kohaldu"
        })
    return results

# --- TÃ¶Ã¶tlemine ---
def process_word_analysis(word: str):
    context_path = os.path.join(DATA_FOLDER, f"{word}_full_context_only.txt")
    if not os.path.exists(context_path):
        print(f"â›” Puudub kontekstifail: {context_path}")
        return None

    with open(context_path, "r", encoding="utf-8") as f:
        lines = [line.strip() for line in f if line.strip()]

    full_text = "\n".join(lines)
    if tokenize_length(full_text) < 120000:
        context = full_text
        print(f"ğŸ“„ Kasutan tÃ¤ielikku konteksti ({len(lines)} rida)")
    else:
        print(f"â„¹ï¸ Fail on suur â€“ kasutatakse embedding-pÃµhist lÃµiguvalikut ({word})")
        index, chunks = ensure_index_exists(word, lines)
        relevant_chunks = get_relevant_chunks_max(word, chunks, index, max_k=150)
        context = "\n---\n".join(relevant_chunks)
        print(f"ğŸ“„ Kasutan {len(relevant_chunks)} kÃµige relevantsemat lÃµiku")

    prompt = create_analysis_prompt(word)

    try:
        reply = get_completion(prompt, context)

        print("\n" + "="*80)
        print(f"ğŸ¤– MUDELI VASTUS sÃµnale '{word}':")
        print("="*80)
        print(reply)
        print("="*80)

        safe_word = sanitize_filename(word)
        out_path = os.path.join(OUTPUT_FOLDER, f"{safe_word}_analysis.txt")
        with open(out_path, "w", encoding="utf-8") as out_f:
            out_f.write(reply)

        parsed_results = parse_analysis_response(reply, word)

        print(f"\nğŸ“Š PARSITUD TULEMUS:")
        print(f"   ğŸ“ TÃ¤hendusi kokku (read): {len(parsed_results)}")
        for result in parsed_results:
            print(f"   {result['TÃ¤henduse nr']}. {result['TÃ¤hendus'][:50]}{'...' if len(result['TÃ¤hendus']) > 50 else ''}")
            print(f"      ğŸ“ˆ Sagedus: {result['Sagedus']}")
            print(f"      ğŸ“‹ Register: {result['Tekstiregister']} ({result['Registri kindlus']})")
            print(f"      ğŸ·ï¸ MÃ¤rgend: {result['RegistrimÃ¤rk']}")

        print(f"âœ… {word} â€” AnalÃ¼Ã¼s lÃµpetatud\n")
        return parsed_results

    except Exception as e:
        print(f"âŒ Viga sÃµnaga {word}: {e}")
        return None

# --- PÃµhiprogramm ---
def main():
    all_rows = []

    # Loeme sisendfaili
    with open("sisend.txt", newline="", encoding="utf-8") as csvfile:
        reader = csv.reader(csvfile, delimiter="\t")
        first_row = next(reader, None)
        # Kui on pÃ¤is, proovi tuvastada; muidu loe kÃµiki
        if first_row and len(first_row) == 1 and first_row[0].lower() in ("sÃµna", "sona", "word"):
            words = [row[0].strip() for row in reader if len(row) >= 1 and row[0].strip()]
        else:
            words = []
            if first_row and len(first_row) >= 1 and first_row[0].strip():
                words.append(first_row[0].strip())
            for row in reader:
                if len(row) >= 1 and row[0].strip():
                    words.append(row[0].strip())

    for i, word in enumerate(words, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“ ANALÃœÃœSIN ({i}/{len(words)}): '{word}'")
        print(f"{'='*60}")

        result = process_word_analysis(word)
        if result:
            all_rows.extend(result)
        else:
            print(f"âš ï¸ Lisame tÃ¼hja rea jÃ¤rjekorra sÃ¤ilitamiseks")
            all_rows.append({
                "SÃµna": word,
                "TÃ¤henduse nr": 1,
                "TÃ¤hendus": "tÃ¶Ã¶tlemata",
                "TÃ¤henduste arv kokku": 0,
                "Sagedus": "kontekstifail puudub",
                "NÃ¤ited": "ei saadaval",
                "Tekstiregister": "ei mÃ¤Ã¤ratletud",
                "Registri pÃµhjendus": "ei saadaval",
                "Registri kindlus": "pigem ebakindel",
                "RegistrimÃ¤rk": "ei kohaldu",
                "MÃ¤rgendi pÃµhjendus": "ei saadaval"
            })

        time.sleep(0.5)

    fieldnames = [
        "SÃµna", "TÃ¤henduse nr", "TÃ¤hendus", "TÃ¤henduste arv kokku",
        "Sagedus", "NÃ¤ited", "Tekstiregister", "Registri pÃµhjendus",
        "Registri kindlus", "RegistrimÃ¤rk", "MÃ¤rgendi pÃµhjendus"
    ]

    with open(FINAL_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=";", quoting=csv.QUOTE_ALL)
        writer.writeheader()
        for row in all_rows:
            writer.writerow(row)

    print(f"\nâœ… LÃµplik fail salvestatud: {FINAL_CSV}")
    print(f"ğŸ“Š Kokku analÃ¼Ã¼situd ridu: {len(all_rows)}")

    # Statistika
    unikaalsed_sÃµnad = len(set(row["SÃµna"] for row in all_rows))
    toÃ¶tletud_sÃµnad = len(set(row["SÃµna"] for row in all_rows if row["TÃ¤hendus"] != "tÃ¶Ã¶tlemata"))
    toÃ¶tlemata_sÃµnad = unikaalsed_sÃµnad - toÃ¶tletud_sÃµnad
    keskmine_tÃ¤hendusi = len(all_rows) / unikaalsed_sÃµnad if unikaalsed_sÃµnad > 0 else 0

    print(f"\nğŸ“ˆ AnalÃ¼Ã¼si statistika:")
    print(f"  Kokku sÃµnu: {unikaalsed_sÃµnad}")
    print(f"  Edukalt tÃ¶Ã¶deldud sÃµnu: {toÃ¶tletud_sÃµnad}")
    print(f"  TÃ¶Ã¶tlemata sÃµnu (puuduvad failid): {toÃ¶tlemata_sÃµnad}")
    print(f"  Keskmine tÃ¤hendusi sÃµna kohta: {keskmine_tÃ¤hendusi:.1f}")

if __name__ == "__main__":
    main()
