#Kood, registrite t√∂√∂r√ºhma 3. katse tarvis. Eesm√§rk on OpenAI mudelile kaasa anda korpusest andmed, mida ta anal√º√ºsima peab. Igale anal√º√ºsitavale s√µnale antakse kaasa ka t√§hendus.
#Kui kontekst on liiga suur, siis see vektoriseeritakse.
#Autor: Eleri Aedmaa

import os
import csv
import openai
import pickle
import faiss
import tiktoken
import pandas as pd
import re
import time
from typing import List
from sentence_transformers import SentenceTransformer

# --- Konfiguratsioon ---
client = openai.OpenAI()
MODEL = "gpt-4o"
EMBED_MODEL = SentenceTransformer("intfloat/multilingual-e5-base")
DATA_FOLDER = "contexts"
OUTPUT_FOLDER = "vastused"
FINAL_CSV = "vastused_koond.csv"

os.makedirs(OUTPUT_FOLDER, exist_ok=True)
os.makedirs("vector_cache", exist_ok=True)

# --- Abi funktsioonid ---
def tokenize_length(text: str, model=MODEL):
    enc = tiktoken.encoding_for_model(model)
    return len(enc.encode(text))

def build_faiss_index(chunks: List[str]):
    passages = [f"passage: {chunk}" for chunk in chunks]
    embeddings = EMBED_MODEL.encode(passages, show_progress_bar=False)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return index, embeddings

def save_index(index, chunks, path):
    faiss.write_index(index, f"{path}.faiss")
    with open(f"{path}_chunks.pkl", "wb") as f:
        pickle.dump(chunks, f)

def load_index(path):
    index = faiss.read_index(f"{path}.faiss")
    with open(f"{path}_chunks.pkl", "rb") as f:
        chunks = pickle.load(f)
    return index, chunks

def ensure_index_exists(word: str, full_lines: List[str]):
    index_path = os.path.join("vector_cache", word)
    if os.path.exists(index_path + ".faiss") and os.path.exists(index_path + "_chunks.pkl"):
        return load_index(index_path)
    
    index, _ = build_faiss_index(full_lines)
    save_index(index, full_lines, index_path)
    return index, full_lines

def get_relevant_chunks_max(query: str, chunks: List[str], index, max_k=None):
    query_vec = EMBED_MODEL.encode([f"query: {query}"], show_progress_bar=False)
    D, I = index.search(query_vec, len(chunks))
    sorted_chunks = [chunks[i] for i in I[0]]
    if max_k:
        return sorted_chunks[:max_k]
    return sorted_chunks

def get_completion(prompt: str, context: str) -> str:
    response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": context}
        ],
        max_tokens=1500,
        temperature=0.1
    )
    return response.choices[0].message.content

def sanitize_filename(text):
    return re.sub(r'[<>:"/\\|?*]', '_', text)[:100]

# --- Prompt ---
def create_prompt(word: str, definition: str):
    return f"""Oled eesti keele s√µnaraamatu koostaja. Sinu √ºlesanne on hinnata, kas s√µnale ‚Äû{word}" tuleb t√§henduses ‚Äû{definition}" lisada registrim√§rgend. Vasta ainult etteantud konteksti p√µhjal ja hoia vastused l√ºhikesed ning konkreetsed.

Vasta j√§rgmistele k√ºsimustele:

1. Otsusta s√µna ‚Äû{word}" t√§henduse ‚Äû{definition}" kohta, kas seda kasutatakse pigem informaalsetes v√µi neutraalsetes/formaalsetes tekstides? Kui sa ei oska eristust teha v√µi see ei tule selgelt esile, siis √ºtle, et ‚Äûei kohaldu". Palun p√µhjenda oma valikut.

2. Too kuni 10 n√§idet antud materjalist, kus s√µna ‚Äû{word}" esineb just selles t√§henduses. Kui n√§iteid on v√§hem, too nii palju, kui leidub.

3. Kui valisid, et s√µna selles t√§henduses esineb pigem *informaalsetes* tekstides, siis:
‚Ä¢ Millise registrim√§rgendeist sellele t√§hendusele lisaksid? (vali v√§hemalt √ºks, v√µid valida mitu):
‚Ä¢ halvustav, harv, k√µnekeelne, lastekeelne, luulekeelne, murdekeelne, rahvakeelne, stiilitundlik, unars√µna, vananenud, vulgaarne
‚Ä¢ P√µhjenda iga m√§rgendivalikut l√ºhidalt.

OLULINE: P√§rast k√ºsimustele vastamist anna oma vastused T√ÑPSELT j√§rgmises struktureeritud formaadis:

VASTUS||TEKSTIREGISTER: [informaalsetes/neutraalsetes-formaalsetes/ei-kohaldu]||P√ïHJENDUS: [l√ºhike p√µhjendus]||N√ÑITED: [n√§ide1; n√§ide2; n√§ide3]||REGISTRIM√ÑRGENDID: [m√§rgend1, m√§rgend2 v√µi ei-kohaldu]||M√ÑRGENDITE-P√ïHJENDUS: [m√§rgend1: p√µhjendus1; m√§rgend2: p√µhjendus2 v√µi ei-kohaldu]||L√ïPP"""

# --- H√ºbriid parsimise funktsioon ---
def parse_response(txt, word, definition):
    result = {
        "S√µna": word,
        "T√§hendus": definition,
        "Tekstiregister": "",
        "P√µhjendus": "",
        "N√§ited (kuni 10)": "",
        "Registrim√§rgend(id)": "",
        "M√§rgendite p√µhjendus": ""
    }
    
    # Otsime struktureeritud vastust
    structured_match = re.search(r'VASTUS\|\|(.*?)\|\|L√ïPP', txt, re.DOTALL)
    
    if structured_match:
        # Struktureeritud vastus leitud
        structured_text = structured_match.group(1)
        parts = structured_text.split('||')
        
        for part in parts:
            part = part.strip()
            
            if part.startswith('TEKSTIREGISTER:'):
                register = part.replace('TEKSTIREGISTER:', '').strip()
                if 'informaalsetes' in register.lower():
                    result["Tekstiregister"] = "informaalsetes"
                elif 'neutraalsetes' in register.lower() or 'formaalsetes' in register.lower():
                    result["Tekstiregister"] = "neutraalsetes/formaalsetes"
                elif 'ei-kohaldu' in register.lower() or 'ei kohaldu' in register.lower():
                    result["Tekstiregister"] = "ei kohaldu"
                else:
                    result["Tekstiregister"] = register
                    
            elif part.startswith('P√ïHJENDUS:'):
                result["P√µhjendus"] = part.replace('P√ïHJENDUS:', '').strip()
                
            elif part.startswith('N√ÑITED:'):
                naited_text = part.replace('N√ÑITED:', '').strip()
                if naited_text and 'puuduvad' not in naited_text.lower():
                    examples = [ex.strip().strip('"\'‚Äû"') for ex in naited_text.split(';') if ex.strip()]
                    if examples:
                        numbered_examples = []
                        for i, example in enumerate(examples[:10], 1):
                            numbered_examples.append(f"{i}. {example}")
                        result["N√§ited (kuni 10)"] = ' | '.join(numbered_examples)
                    else:
                        result["N√§ited (kuni 10)"] = "n√§ited puuduvad"
                else:
                    result["N√§ited (kuni 10)"] = "n√§ited puuduvad"
                    
            elif part.startswith('REGISTRIM√ÑRGENDID:'):
                margendid_text = part.replace('REGISTRIM√ÑRGENDID:', '').strip()
                if 'ei-kohaldu' in margendid_text.lower() or 'ei kohaldu' in margendid_text.lower():
                    result["Registrim√§rgend(id)"] = "ei kohaldu"
                else:
                    margendid = [m.strip() for m in margendid_text.split(',') if m.strip()]
                    result["Registrim√§rgend(id)"] = ", ".join(margendid) if margendid else "ei kohaldu"
                    
            elif part.startswith('M√ÑRGENDITE-P√ïHJENDUS:'):
                pohjendused_text = part.replace('M√ÑRGENDITE-P√ïHJENDUS:', '').strip()
                if 'ei-kohaldu' in pohjendused_text.lower() or 'ei kohaldu' in pohjendused_text.lower():
                    result["M√§rgendite p√µhjendus"] = "ei kohaldu"
                else:
                    result["M√§rgendite p√µhjendus"] = pohjendused_text
    
    else:
        # Struktureeritud vastust ei leitud, kasutame vana parsimisloogikat
        print("   ‚ö†Ô∏è Struktureeritud vastust ei leitud, kasutame vaba teksti parsimist")
        
        # 1. Tekstiregister
        first_sentence_match = re.search(r'1\.\s*[^\.]*?(informaalsetes|neutraalsetes|formaalsetes|ei kohaldu)[^\.]*\.', txt, re.IGNORECASE)
        if first_sentence_match:
            register_word = first_sentence_match.group(1).lower()
            if 'informaalsetes' in register_word:
                result["Tekstiregister"] = "informaalsetes"
            elif 'neutraalsetes' in register_word or 'formaalsetes' in register_word:
                result["Tekstiregister"] = "neutraalsetes/formaalsetes"
            elif 'ei kohaldu' in register_word:
                result["Tekstiregister"] = "ei kohaldu"
        
        # 2. P√µhjendus
        pohjendus_match = re.search(r'1\.[^\.]*\.\s*([^2]*?)(?=2\.|$)', txt, re.DOTALL)
        if pohjendus_match:
            pohjendus_text = pohjendus_match.group(1).strip()
            pohjendus_text = re.sub(r'Palun p√µhjenda oma valikut\.?\s*[-‚Äì]?\s*', '', pohjendus_text, flags=re.IGNORECASE)
            pohjendus_text = re.sub(r'\s+', ' ', pohjendus_text)
            result["P√µhjendus"] = pohjendus_text.strip()
        
        # 3. N√§ited  
        naited_match = re.search(r'2\.\s*([^3]*?)(?=3\.|VASTUS|$)', txt, re.DOTALL)
        if naited_match:
            naited_text = naited_match.group(1).strip()
            if 'puudub' not in naited_text.lower() and 'ei saa' not in naited_text.lower():
                quotes_pattern = r'[‚Äû"\'"]([^‚Äû"\']*?)[‚Äû"\'"]\s*[-‚Äì]?'
                quotes_matches = re.findall(quotes_pattern, naited_text)
                if quotes_matches:
                    numbered_examples = []
                    for i, example in enumerate(quotes_matches[:10], 1):
                        numbered_examples.append(f"{i}. {example}")
                    result["N√§ited (kuni 10)"] = ' | '.join(numbered_examples)
                else:
                    result["N√§ited (kuni 10)"] = "n√§ited puuduvad"
            else:
                result["N√§ited (kuni 10)"] = "n√§ited puuduvad"
    
    # Vaikev√§√§rtused
    if not result["Tekstiregister"]:
        result["Tekstiregister"] = "ei m√§√§ratletud"
    if not result["P√µhjendus"]:
        result["P√µhjendus"] = "p√µhjendus puudub"
    if not result["N√§ited (kuni 10)"]:
        result["N√§ited (kuni 10)"] = "n√§ited puuduvad"
    if not result["Registrim√§rgend(id)"]:
        result["Registrim√§rgend(id)"] = "ei kohaldu"
    if not result["M√§rgendite p√µhjendus"]:
        result["M√§rgendite p√µhjendus"] = "ei kohaldu"
    
    return result

# --- S√µna t√∂√∂tlemise funktsioon---
def process_word(word: str, definition: str):
    context_path = os.path.join(DATA_FOLDER, f"{word}_full_context_only.txt")
    if not os.path.exists(context_path):
        print(f"‚õî Puudub kontekstifail: {context_path}")
        return None

    with open(context_path, "r", encoding="utf-8") as f:
        lines = [line.strip() for line in f if line.strip()]

    full_text = "\n".join(lines)
    if tokenize_length(full_text) < 120000:
        context = full_text
        print(f"üìÑ Kasutan t√§ielikku konteksti ({len(lines)} rida)")
    else:
        print(f"‚ÑπÔ∏è Fail on suur ‚Äì kasutatakse embedding-p√µhist l√µiguvalikut ({word})")
        index, chunks = ensure_index_exists(word, lines)
        relevant_chunks = get_relevant_chunks_max(word, chunks, index, max_k=100)
        context = "\n---\n".join(relevant_chunks)
        print(f"üìÑ Kasutan {len(relevant_chunks)} k√µige relevantsemast l√µiku")

    prompt = create_prompt(word, definition)

    try:
        reply = get_completion(prompt, context)
        
        # Prindime mudeli toorvastuse
        print("\n" + "="*80)
        print(f"ü§ñ MUDELI VASTUS s√µnale '{word}' ({definition}):")
        print("="*80)
        print(reply)
        print("="*80)
        
        # Salvesta toorvastus faili (su stiilis)
        safe_word = sanitize_filename(word)
        safe_def = sanitize_filename(definition)
        out_path = os.path.join(OUTPUT_FOLDER, f"{safe_word}__{safe_def}.txt")
        with open(out_path, "w", encoding="utf-8") as out_f:
            out_f.write(reply)
        
        # Parsime vastuse
        parsed_result = parse_response(reply, word, definition)
        
        # Prindime parsimise tulemuse
        print(f"\nüìä PARSITUD TULEMUS:")
        print(f"   üìù Tekstiregister: {parsed_result['Tekstiregister']}")
        print(f"   üí≠ P√µhjendus: {parsed_result['P√µhjendus'][:100]}{'...' if len(parsed_result['P√µhjendus']) > 100 else ''}")
        print(f"   üìã N√§iteid leitud: {len(parsed_result['N√§ited (kuni 10)'].split('|')) if parsed_result['N√§ited (kuni 10)'] != 'n√§ited puuduvad' else 0}")
        print(f"   üè∑Ô∏è Registrim√§rgendid: {parsed_result['Registrim√§rgend(id)']}")
        if parsed_result['M√§rgendite p√µhjendus'] != "ei kohaldu":
            print(f"   ‚ùì M√§rgendite p√µhjendused:")
            for pohjendus in parsed_result['M√§rgendite p√µhjendus'].split(';'):
                if pohjendus.strip():
                    print(f"      ‚Ä¢ {pohjendus.strip()}")
                    
        # Hoiatus kui m√§rgendeid on aga p√µhjendusi ei ole
        margendid = [m.strip() for m in parsed_result['Registrim√§rgend(id)'].split(',') if m.strip() != 'ei kohaldu']
        if margendid and parsed_result['M√§rgendite p√µhjendus'] == "ei kohaldu":
            print(f"   ‚ö†Ô∏è HOIATUS: M√§rgendid valitud ({margendid}) aga p√µhjendused puuduvad!")
        elif margendid:
            pohjenduste_arv = len([p for p in parsed_result['M√§rgendite p√µhjendus'].split(';') if p.strip()])
            if len(margendid) != pohjenduste_arv:
                print(f"   ‚ö†Ô∏è HOIATUS: M√§rgendeid {len(margendid)}, aga p√µhjendusi {pohjenduste_arv}")
        
        print(f"‚úÖ {word} ‚Äî T√∂√∂tlemine l√µpetatud\n")
        
        return parsed_result

    except Exception as e:
        print(f"‚ùå Viga s√µnaga {word}: {e}")
        return None

# --- P√µhiprogramm ---
def main():
    all_rows = []
    
    with open("sisend.tsv", newline="", encoding="utf-8") as csvfile:
        reader = csv.reader(csvfile, delimiter="\t")
        next(reader)  # j√§ta p√§is vahele
        entries = [(row[0].strip(), row[1].strip()) for row in reader if len(row) >= 2]
    
    for i, (word, definition) in enumerate(entries, 1):
        print(f"\n{'='*60}")
        print(f"üìù T√ñ√ñTLEN ({i}/{len(entries)}): '{word}' - '{definition}'")
        print(f"{'='*60}")
        
        result = process_word(word, definition)
        if result:
            all_rows.append(result)
        else:
            # Lisa t√ºhi rida j√§rjekorra s√§ilitamiseks
            print(f"‚ö†Ô∏è Lisame t√ºhja rea j√§rjekorra s√§ilitamiseks")
            all_rows.append({
                "S√µna": word,
                "T√§hendus": definition,
                "Tekstiregister": "t√∂√∂tlemata",
                "P√µhjendus": "kontekstifail puudub",
                "N√§ited (kuni 10)": "n√§ited puuduvad",
                "Registrim√§rgend(id)": "ei kohaldu",
                "M√§rgendite p√µhjendus": "ei kohaldu"
            })
        
        time.sleep(0.5)  # V√§ike paus

    # Salvesta CSV
    fieldnames = [
        "S√µna", "T√§hendus", "Tekstiregister", "P√µhjendus",
        "N√§ited (kuni 10)", "Registrim√§rgend(id)", "M√§rgendite p√µhjendus"
    ]

    with open(FINAL_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=";", quoting=csv.QUOTE_ALL)
        writer.writeheader()
        for row in all_rows:
            writer.writerow(row)

    print(f"\n‚úÖ L√µplik fail salvestatud: {FINAL_CSV}")
    print(f"üìä Kokku t√∂√∂deldud {len(all_rows)} kirjet")

    # Statistika
    tekstiregister_stats = {}
    for row in all_rows:
        reg = row["Tekstiregister"]
        tekstiregister_stats[reg] = tekstiregister_stats.get(reg, 0) + 1

    print("\nüìà Tekstiregistri statistika:")
    for reg, count in tekstiregister_stats.items():
        print(f"  {reg}: {count}")

if __name__ == "__main__":
    main()