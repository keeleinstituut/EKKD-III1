#Kood registrite tÃ¶Ã¶rÃ¼hma 3. katse tarvis. EesmÃ¤rk on Anthropicu mudelile kaasa anda korpusest andmed, mida ta analÃ¼Ã¼sima peab. SÃµna antakse ilma tÃ¤henduseta.
#Kui kontekst on liiga suur, siis see vektoriseeritakse.
#Autor: Eleri Aedmaa

import os
import csv
import anthropic
import pickle
import faiss
import tiktoken
import pandas as pd
import re
import time
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer

# --- Konfiguratsioon ---
client = anthropic.Anthropic()
MODEL = "claude-3-7-sonnet-20250219"  # Claude Sonnet 3.7
EMBED_MODEL = SentenceTransformer("intfloat/multilingual-e5-base")
DATA_FOLDER = "contexts"
OUTPUT_FOLDER = "vastused"
FINAL_CSV = "vastused_koond.csv"

os.makedirs(OUTPUT_FOLDER, exist_ok=True)
os.makedirs("vector_cache", exist_ok=True)

# --- Abi funktsioonid ---
def tokenize_length(text: str):
    enc = tiktoken.get_encoding("cl100k_base")
    return len(enc.encode(text))

def build_faiss_index(chunks: List[str]):
    passages = [f"passage: {chunk}" for chunk in chunks]
    embeddings = EMBED_MODEL.encode(passages, show_progress_bar=False)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return index, embeddings

def save_index(index, chunks, path):
    faiss.write_index(index, f"{path}.faiss")
    with open(f"{path}_chunks.pkl", "wb") as f:
        pickle.dump(chunks, f)

def load_index(path):
    index = faiss.read_index(f"{path}.faiss")
    with open(f"{path}_chunks.pkl", "rb") as f:
        chunks = pickle.load(f)
    return index, chunks

def ensure_index_exists(word: str, full_lines: List[str]):
    index_path = os.path.join("vector_cache", word)
    if os.path.exists(index_path + ".faiss") and os.path.exists(index_path + "_chunks.pkl"):
        return load_index(index_path)
    
    index, _ = build_faiss_index(full_lines)
    save_index(index, full_lines, index_path)
    return index, full_lines

def get_relevant_chunks_max(query: str, chunks: List[str], index, max_k=None):
    query_vec = EMBED_MODEL.encode([f"query: {query}"], show_progress_bar=False)
    D, I = index.search(query_vec, len(chunks))
    sorted_chunks = [chunks[i] for i in I[0]]
    if max_k:
        return sorted_chunks[:max_k]
    return sorted_chunks

def get_completion(prompt: str, context: str) -> str:
    response = client.messages.create(
        model=MODEL,
        system=prompt,
        messages=[
            {"role": "user", "content": context}
        ],
        max_tokens=16000,
        temperature=0.1
    )
    return response.content[0].text

def sanitize_filename(text):
    return re.sub(r'[<>:"/\\|?*]', '_', text)[:100]

# --- Prompt sÃµna analÃ¼Ã¼simiseks ---
def create_analysis_prompt(word: str):
    return f"""Oled eesti keele sÃµnaraamatu koostaja. Sinu Ã¼lesanne on analÃ¼Ã¼sida sÃµna â€{word}" kasutust etteantud tekstimaterjalis ja otsustada, kas selle tÃ¤hendustele tuleks lisada registrimÃ¤rgend.

Vasta jÃ¤rgmistele kÃ¼simustele, tuginedes ainult etteantud materjalile:

1. Nimeta sÃµna â€{word}" kÃµik tÃ¤hendused, mida etteantud tekstides nÃ¤ed. Ã„ra erista alammÃµisteid erinevateks tÃ¤hendusteks (nÃ¤iteks â€alukad" ei tÃ¤henda eraldi â€aluspesu" ja â€vanaema aluspÃ¼kse", vaid Ã¼ksnes â€aluspesu").

2. Nimeta sÃµna â€{word}" erinevate tÃ¤henduste arv.

3. Iga tÃ¤henduse juurde lisa, kas sÃµna on selles tÃ¤henduses sage, keskmine vÃµi harv. SagedusrÃ¼hm vali vÃµrdluses sÃµna teiste tÃ¤hendustega.

4. Too iga tÃ¤henduse kohta etteantud materjalist 3 nÃ¤itelauset. Kui neid on andmetes vÃ¤hem, siis too nii palju, kui leidub.

5. Otsusta sÃµna iga tÃ¤henduse kohta, kas seda kasutatakse pigem informaalsetes vÃµi neutraalsetes/formaalsetes tekstides? Kui sa ei oska eristust teha vÃµi see ei tule selgelt esile, siis Ã¼tle, et â€ei kohaldu". Palun pÃµhjenda oma valikut 5-10 lausega.

6. Kui valid â€ei kohaldu", siis ja ainult siis vaata enda treeningandmetesse ja otsusta selle pÃµhjal. Palun pÃµhjenda oma valikut 5-10 lausega.

7. Kui mÃµnda tÃ¤hendust kasutatakse pigem informaalsetes tekstides, siis vali sellele sobiv registrimÃ¤rgend jÃ¤rgmistest:
â€¢ halvustav (nÃ¤iteks ajuhÃ¤lvik, debiilik, inimrÃ¤mps)
â€¢ harv (nÃ¤iteks ahvatama, mÃµistamisi, siinap). MÃ¤rgend â€harv" vali iga kord, kui tÃ¤hendust leidub etteantud tekstimaterjalis vÃ¤he.
â€¢ kÃµnekeelne (nÃ¤iteks igastahes, nokats, Ã¤ra flippima)
â€¢ lastekeelne (nÃ¤iteks jÃ¤nku, kÃ¤tu, nuku)
â€¢ luulekeelne (nÃ¤iteks ehavalu, koidukuld, meeleheit)
â€¢ murdekeelne (nÃ¤iteks hÃ¤mmelgas, jÃµÃµrdlik, kidelema)
â€¢ rahvakeelne (nÃ¤iteks heinakuu, viinakuu, mÃ¤nniseen)
â€¢ stiilitundlik (nÃ¤iteks armastet, kirjutet, seitung)
â€¢ unarsÃµna (nÃ¤iteks absurdum, Ã¶Ã¶p)
â€¢ vananenud (nÃ¤iteks automobiil, drogist)
â€¢ vulgaarne (nÃ¤iteks hoorapoeg, koinima, munn)

Iga valiku korral pÃµhjenda 5-10 lausega, miks just see mÃ¤rgend sobib. Igal informaalsel tÃ¤hendusel peab olema vÃ¤hemalt Ã¼ks mÃ¤rgend. Kui sobib mitu, too mitu.

OLULINE: PÃ¤rast kÃ¼simustele vastamist anna oma vastused TÃ„PSELT jÃ¤rgmises struktureeritud formaadis parsimiseks. Kasuta erinevat eraldajat (Â§Â§Â§) iga tÃ¤henduse andmete vahel:

--- STRUKTUREERITUD VASTUS ALGAB ---
TÃ„HENDUSED: kodukitsÂ§Â§Â§Hiina sodiaagimÃ¤rkÂ§Â§Â§halvustav termin politseinikule
TÃ„HENDUSTE-ARV: 3
SAGEDUSED: kodukits-sageÂ§Â§Â§Hiina sodiaagimÃ¤rk-keskmineÂ§Â§Â§halvustav termin politseinikule-harv
NÃ„ITED: kodukits-Kits on vÃ¤ike lehmake|Kitsed on intelligentsed loomad|Kits talub Ã¤Ã¤rmuslikke tingimusiÂ§Â§Â§Hiina sodiaagimÃ¤rk-Kits on sodiaagi kaheksas loom|Kits on sitke ja jÃ¤rjekindelÂ§Â§Â§halvustav termin politseinikule-Miks politseinikud kitsed on|Kriminaalidele tulebki kitse panna
REGISTRID: kodukits-neutraalsetes-formaalsetesÂ§Â§Â§Hiina sodiaagimÃ¤rk-neutraalsetes-formaalsetesÂ§Â§Â§halvustav termin politseinikule-informaalsetes
REGISTRI-PÃ•HJENDUSED: kodukits-Kodukitse tÃ¤hendus on neutraalne ja informatiivne. Seda kasutatakse loomakasvatus- ja pÃµllumajandusalases kirjanduses. Terminoloogia on objektiivne ja faktiline. SÃµnakasutus on ametlik ja teaduslik. Kontekst on tavaliselt hariduslik vÃµi informatsioonialaneÂ§Â§Â§Hiina sodiaagimÃ¤rk-Horoskoobid on neutraalsed kultuuritekstid. Need kuuluvad populaarkultuuri valdkonda. Stiil on kirjeldav ja informeeriv. Kasutus on Ã¼ldlevinud meedias. Puudub emotsionaalne vÃ¤rvitud sÃµnakasutusÂ§Â§Â§halvustav termin politseinikule-Kasutatakse vaenulikus vÃµi kriitilises kontekstis. SÃµnakasutus on emotsionaalselt laetud. Esineb tavaliselt konfliktides vÃµi protestides. VÃ¤ljendab negatiivset suhtumist vÃµimuesindajatesse. Kontekst on sageli poliitiliselt pingeline
MÃ„RGENDID: kodukits-ei-kohalduÂ§Â§Â§Hiina sodiaagimÃ¤rk-ei-kohalduÂ§Â§Â§halvustav termin politseinikule-halvustav
MÃ„RGENDITE-PÃ•HJENDUSED: kodukits-ei-kohalduÂ§Â§Â§Hiina sodiaagimÃ¤rk-ei-kohalduÂ§Â§Â§halvustav termin politseinikule-Selgelt negatiivne suhtumine politseinike suhtes. SÃµna kannab halvustavat konnotatsiooni. Kasutatakse derogatiivses mÃµttes. VÃ¤ljendab pÃµlgust vÃµi vihkamist. EesmÃ¤rk on alandada ja maha teha. Kuulub konflikti- ja protestikeele hulka
--- STRUKTUREERITUD VASTUS LÃ•PEB ---"""

# --- Parandatud parsimise funktsioon ---
def parse_analysis_response(txt: str, word: str) -> List[Dict[str, Any]]:
    """
    Tagastab listi, kus iga element on Ã¼ks tÃ¤hendus koos kÃµigi andmetega
    """
    results = []
    
    try:
        # Otsime struktureeritud vastust mÃ¤rgendite vahelt
        structured_match = re.search(r'--- STRUKTUREERITUD VASTUS ALGAB ---(.*?)--- STRUKTUREERITUD VASTUS LÃ•PEB ---', txt, re.DOTALL)
        
        if not structured_match:
            print("   âš ï¸ Struktureeritud vastust ei leitud, parsime kogu teksti")
            structured_text = txt
        else:
            structured_text = structured_match.group(1)
        
        lines = structured_text.split('\n')
        data = {}
        
        for line in lines:
            line = line.strip()
            if ':' in line and not line.startswith('http'):
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip()
                data[key] = value
        
        # Parsime tÃ¤hendused (kasutame Â§Â§Â§ eraldajat)
        tÃ¤hendused = []
        if 'TÃ„HENDUSED' in data:
            tÃ¤hendused = [t.strip() for t in data['TÃ„HENDUSED'].split('Â§Â§Â§') if t.strip()]
        
        # Parsime sagedused
        sagedused = []
        if 'SAGEDUSED' in data:
            sagedused_raw = data['SAGEDUSED'].split('Â§Â§Â§')
            for item in sagedused_raw:
                if '-' in item:
                    sagedused.append(item.split('-', 1)[1].strip())
                else:
                    sagedused.append(item.strip())
        
        # Parsime registrid
        registrid = []
        if 'REGISTRID' in data:
            registrid_raw = data['REGISTRID'].split('Â§Â§Â§')
            for item in registrid_raw:
                if '-' in item:
                    registrid.append(item.split('-', 1)[1].strip())
                else:
                    registrid.append(item.strip())
        
        # Parsime registri pÃµhjendused (nÃ¼Ã¼d sÃ¤ilivad pikad tekstid)
        registri_pÃµhjendused = []
        if 'REGISTRI-PÃ•HJENDUSED' in data:
            pÃµhjendused_raw = data['REGISTRI-PÃ•HJENDUSED'].split('Â§Â§Â§')
            for item in pÃµhjendused_raw:
                if '-' in item:
                    registri_pÃµhjendused.append(item.split('-', 1)[1].strip())
                else:
                    registri_pÃµhjendused.append(item.strip())
        
        # Parsime mÃ¤rgendid
        mÃ¤rgendid = []
        if 'MÃ„RGENDID' in data:
            mÃ¤rgendid_raw = data['MÃ„RGENDID'].split('Â§Â§Â§')
            for item in mÃ¤rgendid_raw:
                if '-' in item:
                    mÃ¤rgendid.append(item.split('-', 1)[1].strip())
                else:
                    mÃ¤rgendid.append(item.strip())
        
        # Parsime mÃ¤rgendite pÃµhjendused (nÃ¼Ã¼d sÃ¤ilivad pikad tekstid)
        mÃ¤rgendite_pÃµhjendused = []
        if 'MÃ„RGENDITE-PÃ•HJENDUSED' in data:
            mÃ¤rgendite_pÃµhjendused_raw = data['MÃ„RGENDITE-PÃ•HJENDUSED'].split('Â§Â§Â§')
            for item in mÃ¤rgendite_pÃµhjendused_raw:
                if '-' in item:
                    mÃ¤rgendite_pÃµhjendused.append(item.split('-', 1)[1].strip())
                else:
                    mÃ¤rgendite_pÃµhjendused.append(item.strip())
        
        # Parsime nÃ¤ited
        nÃ¤ited = []
        if 'NÃ„ITED' in data:
            nÃ¤ited_raw = data['NÃ„ITED'].split('Â§Â§Â§')
            for item in nÃ¤ited_raw:
                if '-' in item:
                    nÃ¤ited_part = item.split('-', 1)[1].strip()
                    nÃ¤ited.append(nÃ¤ited_part.replace('|', ' | '))
                else:
                    nÃ¤ited.append(item.strip())
        
        # Loome iga tÃ¤henduse jaoks eraldi kirje
        for i, tÃ¤hendus in enumerate(tÃ¤hendused):
            # VÃµtame andmed jÃ¤rjekorra alusel, aga kontrollime pikkust
            sagedus = sagedused[i] if i < len(sagedused) else "ei mÃ¤Ã¤ratletud"
            nÃ¤ited_text = nÃ¤ited[i] if i < len(nÃ¤ited) else "ei leitud"
            register = registrid[i] if i < len(registrid) else "ei mÃ¤Ã¤ratletud"
            registri_pÃµhjendus = registri_pÃµhjendused[i] if i < len(registri_pÃµhjendused) else "ei mÃ¤Ã¤ratletud"
            mÃ¤rgendid_text = mÃ¤rgendid[i] if i < len(mÃ¤rgendid) else "ei-kohaldu"
            mÃ¤rgendite_pÃµhjendus = mÃ¤rgendite_pÃµhjendused[i] if i < len(mÃ¤rgendite_pÃµhjendused) else "ei-kohaldu"
            
            # Jagame mÃ¤rgendid komaga (kui on mitu)
            mÃ¤rgendid_list = []
            if mÃ¤rgendid_text and mÃ¤rgendid_text != "ei-kohaldu":
                mÃ¤rgendid_list = [m.strip() for m in mÃ¤rgendid_text.split(',') if m.strip()]
            
            # Kui mÃ¤rgendeid pole vÃµi on "ei-kohaldu", teeme Ã¼he rea
            if not mÃ¤rgendid_list or mÃ¤rgendid_text == "ei-kohaldu":
                result = {
                    "SÃµna": word,
                    "TÃ¤henduse nr": i + 1,
                    "TÃ¤hendus": tÃ¤hendus,
                    "TÃ¤henduste arv kokku": data.get('TÃ„HENDUSTE-ARV', str(len(tÃ¤hendused))),
                    "Sagedus": sagedus,
                    "NÃ¤ited": nÃ¤ited_text,
                    "Tekstiregister": register,
                    "Registri pÃµhjendus": registri_pÃµhjendus,
                    "Treeningandmete pÃµhjendus": "ei-kohaldu",
                    "RegistrimÃ¤rk": "ei-kohaldu",
                    "MÃ¤rgendi pÃµhjendus": "ei-kohaldu"
                }
                results.append(result)
            else:
                # Iga mÃ¤rgendi jaoks eraldi rida
                for j, mÃ¤rgend in enumerate(mÃ¤rgendid_list):
                    # Kui on mitu mÃ¤rgendit, kasutame sama pÃµhjendust kÃµigi jaoks
                    # (kuna mÃ¤rgendite pÃµhjendused on tihti Ã¼he tÃ¤henduse kohta koos)
                    mÃ¤rgendi_pÃµhjendus = mÃ¤rgendite_pÃµhjendus if mÃ¤rgendite_pÃµhjendus != "ei-kohaldu" else "ei leitud"
                    
                    result = {
                        "SÃµna": word,
                        "TÃ¤henduse nr": i + 1,
                        "TÃ¤hendus": tÃ¤hendus,
                        "TÃ¤henduste arv kokku": data.get('TÃ„HENDUSTE-ARV', str(len(tÃ¤hendused))),
                        "Sagedus": sagedus,
                        "NÃ¤ited": nÃ¤ited_text,
                        "Tekstiregister": register,
                        "Registri pÃµhjendus": registri_pÃµhjendus,
                        "Treeningandmete pÃµhjendus": "ei-kohaldu",
                        "RegistrimÃ¤rk": mÃ¤rgend.strip(),
                        "MÃ¤rgendi pÃµhjendus": mÃ¤rgendi_pÃµhjendus
                    }
                    results.append(result)
            
            print(f"   âœ… TÃ¤hendus {i+1}: {tÃ¤hendus}")
            print(f"      ğŸ“ˆ Sagedus: {sagedus}")
            print(f"      ğŸ“Š Register: {register}")
            print(f"      ğŸ” Registri pÃµhjendus: {registri_pÃµhjendus[:100]}{'...' if len(registri_pÃµhjendus) > 100 else ''}")
            print(f"      ğŸ·ï¸ MÃ¤rgendid: {mÃ¤rgendid_text}")
            if mÃ¤rgendite_pÃµhjendus != "ei-kohaldu":
                print(f"      ğŸ“ MÃ¤rgendi pÃµhjendus: {mÃ¤rgendite_pÃµhjendus[:100]}{'...' if len(mÃ¤rgendite_pÃµhjendus) > 100 else ''}")
    
    except Exception as e:
        print(f"   âš ï¸ Parsimise viga: {e}")
        import traceback
        traceback.print_exc()
        results.append({
            "SÃµna": word,
            "TÃ¤henduse nr": 1,
            "TÃ¤hendus": "parsimise viga",
            "TÃ¤henduste arv kokku": 0,
            "Sagedus": "ei mÃ¤Ã¤ratletud",
            "NÃ¤ited": "ei leitud",
            "Tekstiregister": "ei mÃ¤Ã¤ratletud",
            "Registri pÃµhjendus": "ei mÃ¤Ã¤ratletud",
            "Treeningandmete pÃµhjendus": "ei-kohaldu",
            "RegistrimÃ¤rk": "ei-kohaldu",
            "MÃ¤rgendi pÃµhjendus": "ei-kohaldu"
        })
    
    # Kui mingil pÃµhjusel ei ole tulemusi, lisa vÃ¤hemalt Ã¼ks tÃ¼hi kirje
    if not results:
        results.append({
            "SÃµna": word,
            "TÃ¤henduse nr": 1,
            "TÃ¤hendus": "ei mÃ¤Ã¤ratletud",
            "TÃ¤henduste arv kokku": 0,
            "Sagedus": "ei mÃ¤Ã¤ratletud",
            "NÃ¤ited": "ei leitud",
            "Tekstiregister": "ei mÃ¤Ã¤ratletud",
            "Registri pÃµhjendus": "ei mÃ¤Ã¤ratletud",
            "Treeningandmete pÃµhjendus": "ei-kohaldu",
            "RegistrimÃ¤rk": "ei-kohaldu",
            "MÃ¤rgendi pÃµhjendus": "ei-kohaldu"
        })
    
    return results

# --- SÃµna tÃ¶Ã¶tlemise funktsioon ---
def process_word_analysis(word: str):
    context_path = os.path.join(DATA_FOLDER, f"{word}_full_context_only.txt")
    if not os.path.exists(context_path):
        print(f"â›” Puudub kontekstifail: {context_path}")
        return None

    with open(context_path, "r", encoding="utf-8") as f:
        lines = [line.strip() for line in f if line.strip()]

    full_text = "\n".join(lines)
    if tokenize_length(full_text) < 120000:
        context = full_text
        print(f"ğŸ“„ Kasutan tÃ¤ielikku konteksti ({len(lines)} rida)")
    else:
        print(f"â„¹ï¸ Fail on suur â€“ kasutatakse embedding-pÃµhist lÃµiguvalikut ({word})")
        index, chunks = ensure_index_exists(word, lines)
        relevant_chunks = get_relevant_chunks_max(word, chunks, index, max_k=150)
        context = "\n---\n".join(relevant_chunks)
        print(f"ğŸ“„ Kasutan {len(relevant_chunks)} kÃµige relevantsemast lÃµiku")

    prompt = create_analysis_prompt(word)

    try:
        reply = get_completion(prompt, context)
        
        # Prindime mudeli toorvastuse
        print("\n" + "="*80)
        print(f"ğŸ¤– MUDELI VASTUS sÃµnale '{word}':")
        print("="*80)
        print(reply)
        print("="*80)
        
        # Salvesta toorvastus faili
        safe_word = sanitize_filename(word)
        out_path = os.path.join(OUTPUT_FOLDER, f"{safe_word}_analysis.txt")
        with open(out_path, "w", encoding="utf-8") as out_f:
            out_f.write(reply)
        
        # Parsime vastuse
        parsed_results = parse_analysis_response(reply, word)
        
        # Prindime parsimise tulemuse
        print(f"\nğŸ“Š PARSITUD TULEMUS:")
        print(f"   ğŸ“ TÃ¤hendusi kokku: {len(parsed_results)}")
        for result in parsed_results:
            print(f"   {result['TÃ¤henduse nr']}. {result['TÃ¤hendus'][:50]}{'...' if len(result['TÃ¤hendus']) > 50 else ''}")
            print(f"      ğŸ“ˆ Sagedus: {result['Sagedus']}")
            print(f"      ğŸ“‹ Register: {result['Tekstiregister']}")
            print(f"      ğŸ·ï¸ MÃ¤rgend: {result['RegistrimÃ¤rk']}")
        
        print(f"âœ… {word} â€” AnalÃ¼Ã¼s lÃµpetatud\n")
        
        return parsed_results

    except Exception as e:
        print(f"âŒ Viga sÃµnaga {word}: {e}")
        return None

# --- PÃµhiprogramm ---
def main():
    all_rows = []
    
    # Loeme sisend_2.tsv faili
    with open("sisend_2.tsv", newline="", encoding="utf-8") as csvfile:
        reader = csv.reader(csvfile)
        next(reader, None)  # jÃ¤ta pÃ¤is vahele, kui on
        words = [row[0].strip() for row in reader if len(row) >= 1 and row[0].strip()]
    
    for i, word in enumerate(words, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“ ANALÃœÃœSIN ({i}/{len(words)}): '{word}'")
        print(f"{'='*60}")
        
        result = process_word_analysis(word)
        if result:
            all_rows.extend(result)  # Lisame kÃµik tÃ¤hendused
        else:
            # Lisa tÃ¼hi rida jÃ¤rjekorra sÃ¤ilitamiseks
            print(f"âš ï¸ Lisame tÃ¼hja rea jÃ¤rjekorra sÃ¤ilitamiseks")
            all_rows.append({
                "SÃµna": word,
                "TÃ¤henduse nr": 1,
                "TÃ¤hendus": "tÃ¶Ã¶tlemata",
                "TÃ¤henduste arv kokku": 0,
                "Sagedus": "kontekstifail puudub",
                "NÃ¤ited": "ei saadaval",
                "Tekstiregister": "ei mÃ¤Ã¤ratletud",
                "Registri pÃµhjendus": "ei saadaval",
                "Treeningandmete pÃµhjendus": "ei saadaval",
                "RegistrimÃ¤rk": "ei kohaldu",
                "MÃ¤rgendi pÃµhjendus": "ei saadaval"
            })
        
        time.sleep(0.5)  # VÃ¤ike paus

    # Salvesta CSV
    fieldnames = [
        "SÃµna", "TÃ¤henduse nr", "TÃ¤hendus", "TÃ¤henduste arv kokku", "Sagedus", 
        "NÃ¤ited", "Tekstiregister", "Registri pÃµhjendus", "Treeningandmete pÃµhjendus",
        "RegistrimÃ¤rk", "MÃ¤rgendi pÃµhjendus"
    ]

    with open(FINAL_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=";", quoting=csv.QUOTE_ALL)
        writer.writeheader()
        for row in all_rows:
            writer.writerow(row)

    print(f"\nâœ… LÃµplik fail salvestatud: {FINAL_CSV}")
    print(f"ğŸ“Š Kokku analÃ¼Ã¼situd ridu: {len(all_rows)}")

    # Statistika
    unikaalsed_sÃµnad = len(set(row["SÃµna"] for row in all_rows))
    toÃ¶tletud_sÃµnad = len(set(row["SÃµna"] for row in all_rows if row["TÃ¤hendus"] != "tÃ¶Ã¶tlemata"))
    toÃ¶tlemata_sÃµnad = unikaalsed_sÃµnad - toÃ¶tletud_sÃµnad
    keskmine_tÃ¤hendusi = len(all_rows) / unikaalsed_sÃµnad if unikaalsed_sÃµnad > 0 else 0

    print(f"\nğŸ“ˆ AnalÃ¼Ã¼si statistika:")
    print(f"  Kokku sÃµnu: {unikaalsed_sÃµnad}")
    print(f"  Edukalt tÃ¶Ã¶deldud sÃµnu: {toÃ¶tletud_sÃµnad}")
    print(f"  TÃ¶Ã¶tlemata sÃµnu (puuduvad failid): {toÃ¶tlemata_sÃµnad}")
    print(f"  Keskmine tÃ¤hendusi sÃµna kohta: {keskmine_tÃ¤hendusi:.1f}")

if __name__ == "__main__":
    main()